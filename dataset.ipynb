{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/MLinApp-polito/2025-machine-learning-in-applications-project-mlia-2025-fp06.git"
      ],
      "metadata": {
        "id": "8E0V6BptS81H"
      },
      "id": "8E0V6BptS81H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4fc5c38",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-16T21:48:27.622314Z",
          "iopub.status.busy": "2025-05-16T21:48:27.621519Z",
          "iopub.status.idle": "2025-05-16T21:48:44.384796Z",
          "shell.execute_reply": "2025-05-16T21:48:44.384006Z",
          "shell.execute_reply.started": "2025-05-16T21:48:27.622283Z"
        },
        "id": "f4fc5c38",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!apt update && apt install -y openslide-tools\n",
        "!pip install openslide-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce9e789b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-16T21:48:44.386332Z",
          "iopub.status.busy": "2025-05-16T21:48:44.386099Z",
          "iopub.status.idle": "2025-05-16T21:48:45.694555Z",
          "shell.execute_reply": "2025-05-16T21:48:45.694024Z",
          "shell.execute_reply.started": "2025-05-16T21:48:44.386307Z"
        },
        "id": "ce9e789b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import sys\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "sys.path.append('tempProjectRepo/mesothelioma_project/src')\n",
        "from wsi_utils import load_wsi, extract_patches, count_patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "097c45a3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-16T21:48:45.722009Z",
          "iopub.status.busy": "2025-05-16T21:48:45.721733Z",
          "iopub.status.idle": "2025-05-16T21:48:45.737002Z",
          "shell.execute_reply": "2025-05-16T21:48:45.736382Z",
          "shell.execute_reply.started": "2025-05-16T21:48:45.721991Z"
        },
        "id": "097c45a3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data_csv = \"tempProjectRepo/mesothelioma_project/data/raw-data.csv\"\n",
        "output_dir = \"tempProjectRepo/mesothelioma_project/data/patches\"\n",
        "\n",
        "diagnosis_map = {\"E\": \"epithelioid\", \"S\": \"sarcomatoid\", \"B\": \"biphasic\"}\n",
        "\n",
        "df = pd.read_csv(data_csv, delimiter=r\"\\s+\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32abfa0f",
      "metadata": {
        "id": "32abfa0f"
      },
      "source": [
        "## Finetuning satTresh on the patches of the first slide"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "slide = load_wsi(\"M-101.ndpi\")\n",
        "values = range(15, 45, 5)\n",
        "dir = \"patches_test\"\n",
        "\n",
        "for satThresh in values:\n",
        "    print(f\"Tresh = {satThresh} -> {count_patches(slide, 1, satThresh)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hac7V0H6TGAm",
        "outputId": "8aa3fb5f-c478-443b-a231-d228832d5e7f"
      },
      "id": "Hac7V0H6TGAm",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tresh = 15 -> 2579\n",
            "Tresh = 20 -> 2315\n",
            "Tresh = 25 -> 2121\n",
            "Tresh = 30 -> 1962\n",
            "Tresh = 35 -> 1704\n",
            "Tresh = 40 -> 1403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d4c2c52",
      "metadata": {
        "id": "6d4c2c52"
      },
      "source": [
        "## Count patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36347dd9",
      "metadata": {
        "id": "36347dd9"
      },
      "outputs": [],
      "source": [
        "count_dict = {}\n",
        "\n",
        "for _, row in df.iloc[:].iterrows():\n",
        "    filename = row['filename']\n",
        "    gdrive_id = row['id']\n",
        "    diagnosis_code = row['diagnosis']\n",
        "\n",
        "    name = filename.split(\".\")[0] + \"_\" + diagnosis_code.lower()\n",
        "    count_dict[name] = 0\n",
        "\n",
        "    gdown.download(id=gdrive_id, quiet=True)\n",
        "\n",
        "    # Load the WSI and count the patches\n",
        "    slide = load_wsi(filename)\n",
        "    count_dict[name] = count_patches(slide)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S9p53hfvU3fS",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-16T19:28:14.102339Z",
          "iopub.status.busy": "2025-05-16T19:28:14.101767Z",
          "iopub.status.idle": "2025-05-16T19:28:14.110536Z",
          "shell.execute_reply": "2025-05-16T19:28:14.109868Z",
          "shell.execute_reply.started": "2025-05-16T19:28:14.102320Z"
        },
        "id": "S9p53hfvU3fS",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def topk_wsi_names(dict_count_patches, k=5):\n",
        "\n",
        "    # print(dict_count_patches)\n",
        "\n",
        "    # Idea to realize the function\n",
        "    # get all names, then create three masks:\n",
        "    # - e_mask, b_mask, s_mask\n",
        "    # for key in keys key.split('_')[1], then store info about index in the corresponding mask\n",
        "\n",
        "    d_keys = list(dict_count_patches.keys())\n",
        "\n",
        "    # Mask to each label\n",
        "    e_mask = np.zeros(len(d_keys))\n",
        "    b_mask = np.zeros(len(d_keys))\n",
        "    s_mask = np.zeros(len(d_keys))\n",
        "    for index in range(len(d_keys)):\n",
        "        if 'e' in d_keys[index]:\n",
        "            e_mask[index] = 1\n",
        "        elif 'b' in d_keys[index]:\n",
        "            b_mask[index] = 1\n",
        "        else:\n",
        "            s_mask[index] = 1\n",
        "\n",
        "    # flatter the dict to a list of values ( order is immutated )\n",
        "    np_dict = np.array(list(dict_count_patches.values()))\n",
        "\n",
        "    # get top k featuers for each label ( index i position is the i-th 1 element in mask )\n",
        "    e_topk_indices = np.argpartition(np_dict[e_mask == 1], k-1)[-k:]\n",
        "    b_topk_indices = np.argpartition(np_dict[b_mask == 1], k-1)[-k:]\n",
        "    s_topk_indices = np.argpartition(np_dict[s_mask == 1], k-1)[-k:]\n",
        "\n",
        "    # compute original position with respect to the original dictionary\n",
        "    combinations = [(e_topk_indices, e_mask, 'e'), (b_topk_indices, b_mask, 'b'), (s_topk_indices, s_mask, 's')]\n",
        "\n",
        "    # devo prendere, tra gli indici marcati come 1 in e_mask, gli indici in posizione 1 e in posizione 2 ( scarto prendo prendo scarto)\n",
        "    topk_indices = []\n",
        "    for topk_list, mask, label in combinations:\n",
        "      indices_of_interest = []\n",
        "      #  print(topk_list, mask, label)\n",
        "      for i in range(len(topk_list)):\n",
        "          index = topk_list[i]\n",
        "          for j in range(len(mask)):\n",
        "              if mask[j] == 1:\n",
        "                  if index == 0:\n",
        "                    indices_of_interest.append(j)\n",
        "                    break\n",
        "                  else:\n",
        "                    index -= 1\n",
        "                    continue\n",
        "              else:\n",
        "                  continue\n",
        "        # collecting all indices to easy extract only that ones in the next cell\n",
        "      topk_indices.extend(indices_of_interest)\n",
        "      print(f\"Top {k} indices for label {label}:\", end='\\t')\n",
        "      for index in indices_of_interest:\n",
        "        print(d_keys[index], end= '\\t')\n",
        "      print()\n",
        "\n",
        "    return topk_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jRhtmxKujDt-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRhtmxKujDt-",
        "outputId": "9260f3db-e6d7-4ab3-9c5a-f4dc1da26032"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 5 indices for label e:\tM-59_e\tM-13_e\tM-70_e\tM-68_e\tM-85_e\t\n",
            "Top 5 indices for label b:\tM-30_b\tM-73_b\tM-108_b\tM-90_b\tM-92_b\t\n",
            "Top 5 indices for label s:\tM-65_s\tM-101_s\tM-86_s\tM-114_s\tM-87_s\t\n"
          ]
        }
      ],
      "source": [
        "topk_indices = topk_wsi_names(count_dict, k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b20846b2",
      "metadata": {
        "id": "b20846b2"
      },
      "source": [
        "## Segmentation and Patching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9d4a133",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-16T21:48:45.751630Z",
          "iopub.status.busy": "2025-05-16T21:48:45.751354Z",
          "iopub.status.idle": "2025-05-16T22:57:07.807094Z",
          "shell.execute_reply": "2025-05-16T22:57:07.806356Z",
          "shell.execute_reply.started": "2025-05-16T21:48:45.751606Z"
        },
        "id": "e9d4a133",
        "trusted": true,
        "outputId": "0c7954cf-a54c-4e1a-d0a2-2aa14b2b2f8c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [1:08:22<00:00, 273.47s/it]\n"
          ]
        }
      ],
      "source": [
        "for _, row in tqdm(df.iloc[topk_indices].iterrows(), total=len(topk_indices)):\n",
        "    filename = row['filename']\n",
        "    gdrive_id = row['id']\n",
        "    diagnosis_code = row['diagnosis']\n",
        "    diagnosis_name = diagnosis_map[diagnosis_code]\n",
        "\n",
        "    gdown.download(id=gdrive_id, quiet=True)\n",
        "\n",
        "    slide_id = os.path.splitext(filename)[0]\n",
        "    slide_output_dir = os.path.join(output_dir, diagnosis_name, slide_id)\n",
        "\n",
        "    # Load and process the WSI\n",
        "    slide = load_wsi(filename)\n",
        "    extract_patches(slide, slide_output_dir)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "32abfa0f",
        "6d4c2c52"
      ],
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 7438133,
          "sourceId": 11838843,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31041,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}