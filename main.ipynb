{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cde661",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/andreazenotto/tempProjectRepo.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fc5c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!apt update && apt install -y openslide-tools\n",
    "!pip install openslide-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9e789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.append('tempProjectRepo/mesothelioma_project/src')\n",
    "from wsi_utils import load_wsi, extract_patches, count_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c45a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv = \"tempProjectRepo/mesothelioma_project/data/raw-data.csv\"\n",
    "output_dir = \"tempProjectRepo/mesothelioma_project/data/patches\"\n",
    "\n",
    "diagnosis_map = {\"E\": \"epithelioid\", \"S\": \"sarcomatoid\", \"B\": \"biphasic\"}\n",
    "\n",
    "df = pd.read_csv(data_csv, delimiter=r\"\\s+\")\n",
    "start_idx = 0\n",
    "end_idx = len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32abfa0f",
   "metadata": {},
   "source": [
    "## Finetuning satTresh on the patches of the first slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1dcb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "slide = load_wsi(\"M-1.ndpi\")\n",
    "values = [23, 25, 27, 29, 30]\n",
    "\n",
    "for satThresh in values:\n",
    "    print(f\"Tresh = {satTresh} -> {count_patches(slide, \"patches_test\", level=1, thresh=satThresh)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4c2c52",
   "metadata": {},
   "source": [
    "## Count patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7838aac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_wsi_names(dict_count_patches, k=5):\n",
    "\n",
    "    # print(dict_count_patches)\n",
    "\n",
    "    # Idea to realize the function\n",
    "    # get all names, then create three masks:\n",
    "    # - e_mask, b_mask, s_mask\n",
    "    # for key in keys key.split('_')[1], then store info about index in the corresponding mask\n",
    "\n",
    "    d_keys = list(dict_count_patches.keys())\n",
    "\n",
    "    # Mask to each label\n",
    "    e_mask = np.zeros(len(d_keys))\n",
    "    b_mask = np.zeros(len(d_keys))\n",
    "    s_mask = np.zeros(len(d_keys))\n",
    "    for index in range(len(d_keys)):\n",
    "        if 'epithelioid' in d_keys[index]:\n",
    "            e_mask[index] = 1\n",
    "        elif 'biphasic' in d_keys[index]:\n",
    "            b_mask[index] = 1\n",
    "        else:\n",
    "            s_mask[index] = 1\n",
    "\n",
    "    # flatter the dict to a list of values ( order is immutated )\n",
    "    np_dict = np.array(list(dict_count_patches.values()))\n",
    "\n",
    "    # get top k featuers for each label ( index i position is the i-th 1 element in mask )\n",
    "    e_topk_indices = np.argpartition(np_dict[e_mask == 1], -k)[-k:]\n",
    "    b_topk_indices = np.argpartition(np_dict[b_mask == 1], -k)[-k:]\n",
    "    s_topk_indices = np.argpartition(np_dict[s_mask == 1], -k)[-k:]\n",
    "\n",
    "    # compute original position with respect to the original dictionary\n",
    "    combinations = [(e_topk_indices, e_mask, 'e'), (b_topk_indices, b_mask, 'b'), (s_topk_indices, s_mask, 's')]\n",
    "\n",
    "    # devo prendere, tra gli indici marcati come 1 in e_mask, gli indici in posizione 1 e in posizione 2 ( scarto prendo prendo scarto)\n",
    "    topk_indices = []\n",
    "    for topk_list, mask, label in combinations:\n",
    "      indices_of_interest = []\n",
    "      #  print(topk_list, mask, label)\n",
    "      for i in range(len(topk_list)):\n",
    "          index = topk_list[i]\n",
    "          for j in range(len(mask)):\n",
    "              if mask[j] == 1:\n",
    "                  if index == 0:\n",
    "                    indices_of_interest.append(j)\n",
    "                    break\n",
    "                  else:\n",
    "                    index -= 1\n",
    "                    continue\n",
    "              else:\n",
    "                  continue\n",
    "\n",
    "      # collecting all indices to easy extract only that ones in the next cell\n",
    "      topk_indices.extend(indices_of_interest)\n",
    "      print(f\"Top {k} indices for label {label}:\", end='\\t')\n",
    "      for index in indices_of_interest:\n",
    "        print(d_keys[index], end= '\\t')\n",
    "      print()\n",
    "\n",
    "      return topk_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36347dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict = {}\n",
    "\n",
    "for _, row in tqdm(df.iloc[start_idx:end_idx].iterrows(), total=len(df)):\n",
    "    filename = row['filename']\n",
    "    gdrive_id = row['id']\n",
    "    diagnosis_code = row['diagnosis']\n",
    "    diagnosis_name = diagnosis_map[diagnosis_code]\n",
    "\n",
    "    name = filename.split(\".\")[0] + \" - \" + diagnosis_name\n",
    "    count_dict[name] = 0\n",
    "\n",
    "    wsi_url = f\"https://drive.google.com/uc?id={gdrive_id}\"\n",
    "    gdown.download(wsi_url, quiet=False)\n",
    "\n",
    "    slide_id = os.path.splitext(filename)[0]\n",
    "    slide_output_dir = os.path.join(output_dir, diagnosis_name, slide_id)\n",
    "\n",
    "    # Load and process the WSI\n",
    "    slide = load_wsi(filename)\n",
    "    count_dict[filename] = count_patches(slide, slide_output_dir, level=1)\n",
    "\n",
    "topk_indices = topk_wsi_names(count_dict, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20846b2",
   "metadata": {},
   "source": [
    "## Segmentation and Patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d4a133",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in tqdm(df.iloc[topk_indices].iterrows(), total=len(df)):\n",
    "    filename = row['filename']\n",
    "    gdrive_id = row['id']\n",
    "    diagnosis_code = row['diagnosis']\n",
    "    diagnosis_name = diagnosis_map[diagnosis_code]\n",
    "\n",
    "    wsi_url = f\"https://drive.google.com/uc?id={gdrive_id}\"\n",
    "    gdown.download(wsi_url, quiet=False)\n",
    "\n",
    "    slide_id = os.path.splitext(filename)[0]\n",
    "    slide_output_dir = os.path.join(output_dir, diagnosis_name, slide_id)\n",
    "\n",
    "    # Load and process the WSI\n",
    "    slide = load_wsi(filename)\n",
    "    extract_patches(slide, slide_output_dir, level=1, threshold=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a3c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "# Percorso della cartella da scaricare\n",
    "folder_path = \"tempProjectRepo/mesothelioma_project/data/patches\"\n",
    "\n",
    "# Nome del file zip da creare\n",
    "zip_filename = \"patches.zip\"\n",
    "\n",
    "# Comprimi la cartella\n",
    "shutil.make_archive(zip_filename.replace(\".zip\", \"\"), 'zip', folder_path)\n",
    "\n",
    "# Scarica il file zip\n",
    "files.download(zip_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
